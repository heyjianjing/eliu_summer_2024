{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Our algorithm"
      ],
      "metadata": {
        "id": "JjgYeNdDVpSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our algorithm after doing gradient descent, Laplace's method for sampling, and Monte Carlo approximation of Bayesian marginalization, we need to compute the (posterior) prediction `mean` and `variance` using the following (code snippet from `10`), before we can plot our results\n",
        "\n",
        "    for i, x_ in enumerate(v_samples_test):\n",
        "        predictive_samples = []\n",
        "        for theta_sample in theta_samples:\n",
        "            predictive_mean = v_samples_test[i, :] @ theta_sample\n",
        "            predictive_var = sigma_d**2\n",
        "            individual_pred_dist = np.random.normal(predictive_mean, np.sqrt(predictive_var), num_samples_predictive_per_theta)\n",
        "            predictive_samples.extend(individual_pred_dist)\n",
        "\n",
        "        posterior_mean_y[i] = np.mean(predictive_samples)\n",
        "        posterior_var_y[i] = np.var(predictive_samples)\n",
        "\n",
        "    k_star_star = rbf_kernel(x_test, x_test, sigma_k)\n",
        "\n",
        "    # Correction step\n",
        "    posterior_var_y = posterior_var_y - np.diag(v_samples_test@v_samples_test.T) + np.diag(k_star_star)\n",
        "\n",
        "    posterior_std_y = np.sqrt(posterior_var_y)"
      ],
      "metadata": {
        "id": "gzJshUa7wkMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correction for one but not for the other..."
      ],
      "metadata": {
        "id": "eupoe_bcWif6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this computation, we simply take the `posterior_mean_y` from monte carlo as it is, while having to make correction to the posterior variance `posterior_var_y`\n",
        "\n",
        "So, `why` is this?"
      ],
      "metadata": {
        "id": "6YCtpg4ZwmLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall in `notes_04`, we described how our virtual samples from eigendecomposition are only approximations of true $\\phi(x)$ induced by RBF kernel. Therefore, from where we get the approximated $\\phi(x)$ matters\n",
        "\n",
        "* In our algorithm, the $\\phi(x)$ for `training data` are obtained using $X_k$, which is computed based on training data only\n",
        "\n",
        "* However, the $\\phi(x)$ for `testing data` are obtained using $X_{t,k}$, which is computed based on training data and testing data. As a result, the $\\phi(x)$ for testing data can only preserve the correlation `between training and testing data`, it cannot preserve the correlation among testing data (which is defined by `k_star_star` in the code snippet)\n"
      ],
      "metadata": {
        "id": "qcicy9Ywhu7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on above, we can see that\n",
        "\n",
        "* if the prediction requires anything related to correlation among testing data, then our approximation will be off and a correction is needed\n",
        "* if the prediction does not require anything related to correlation among testing data, then our approximation will be fine"
      ],
      "metadata": {
        "id": "ePG1lSrCjAbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Analytical solution` of posterior mean and covariance"
      ],
      "metadata": {
        "id": "o5cIp8V-fi-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see it through analytical solution of our algorithm (from eq 2.12 in Rasmussen and Williams book on Gaussian processes)\n",
        "\n",
        "The prediction mean `posterior_mean_y` is computed as\n",
        "\n",
        "$$X_\\text{t,k}(X_k+\\sigma_d^2I)^{-1}y$$\n",
        "\n",
        "while the prediction covariance matrix (the diagonal of which is `posterior_var_y`) is computed as\n",
        "\n",
        "$$X_\\text{test_test}-X_\\text{t,k}(X_k+\\sigma_d^2I)^{-1}X_\\text{t,k}^T$$"
      ],
      "metadata": {
        "id": "4Kh4rlAmwhOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From these two equations, we can see that\n",
        "\n",
        "* prediction `mean` only relies on $X_{t,k}$ and $X_k$, which can be well approximated using dot products of virtual samples obtained in our algorithm since these two are used to generate our virtual samples in the first place\n",
        "* prediction `covariance` matrix requires computation of $X_{test,test}$, which our virtual samples cannot approximate well with dot products"
      ],
      "metadata": {
        "id": "UKZPFDRgg8WR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, only the prediction variance needs to be corrected, by\n",
        "\n",
        "* first, subtracting the inaccurate estimation of `k_star_star` based on the dot product of virtual samples `- np.diag(self.v_samples_test @ self.v_samples_test.T)`\n",
        "* then, adding back the true `k_star_star` based on RBF kernel function `+ np.diag(self.k_star_star)`"
      ],
      "metadata": {
        "id": "0uy9yPENiS3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we only need diagonal components of covariance matrix for our purpose, which is to visualize the prediction variance at each `x_test`, in the future, we can avoid computation of full `k_star_star` and only compute the diagonal of this matrix (which includes just a vector of one's)"
      ],
      "metadata": {
        "id": "xZfMObPajAfb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12O0toN4B0_M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}